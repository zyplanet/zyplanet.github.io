<!DOCTYPE html>





<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.3.0">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.3.0">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.3.0">
  <link rel="mask-icon" href="/images/logo.svg?v=7.3.0" color="#222">

<link rel="stylesheet" href="/css/main.css?v=7.3.0">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '7.3.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '9V8EBROCRY',
      apiKey: '6b200bc430358347660a03d2b1ec3836',
      indexName: 'blog',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: 'Copy',
      copy_success: 'Copied',
      copy_failure: 'Copy failed'
    }
  };
</script>

  <meta name="description" content="Neural Word Embedding as Implicit Matrix Factorization前言尽管嵌入模型很明显是基于分布假设来进行优化，使常出现的word-context对向量内积极大化，并极小化随机word-context对内积。但对于这些优化指标的讨论很少，也不清楚为什么这样能够得到期望的结果。这篇文章对此进行了探讨，表明SGNS(skip-gram with negati">
<meta name="keywords" content="Representation Learning">
<meta property="og:type" content="article">
<meta property="og:title" content="embedding as matrix factorizaiton">
<meta property="og:url" content="https://zyplanet.github.io/2019/10/02/embedding as matrix factorizaiton/index.html">
<meta property="og:site_name" content="diphda">
<meta property="og:description" content="Neural Word Embedding as Implicit Matrix Factorization前言尽管嵌入模型很明显是基于分布假设来进行优化，使常出现的word-context对向量内积极大化，并极小化随机word-context对内积。但对于这些优化指标的讨论很少，也不清楚为什么这样能够得到期望的结果。这篇文章对此进行了探讨，表明SGNS(skip-gram with negati">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://zyplanethome.files.wordpress.com/2019/10/svd1.png">
<meta property="og:image" content="https://zyplanethome.files.wordpress.com/2019/10/svd2.png">
<meta property="og:updated_time" content="2021-09-17T11:08:04.277Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="embedding as matrix factorizaiton">
<meta name="twitter:description" content="Neural Word Embedding as Implicit Matrix Factorization前言尽管嵌入模型很明显是基于分布假设来进行优化，使常出现的word-context对向量内积极大化，并极小化随机word-context对内积。但对于这些优化指标的讨论很少，也不清楚为什么这样能够得到期望的结果。这篇文章对此进行了探讨，表明SGNS(skip-gram with negati">
<meta name="twitter:image" content="https://zyplanethome.files.wordpress.com/2019/10/svd1.png">
  <link rel="canonical" href="https://zyplanet.github.io/2019/10/02/embedding as matrix factorizaiton/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>embedding as matrix factorizaiton | diphda</title>
  <meta name="generator" content="Hexo 3.9.0">
  








  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">
  <div class="container use-motion">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">diphda</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">Study hard and make progress every day.</p>
      
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
      
      
      
        
        <li class="menu-item menu-item-home">
      
    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>Home</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-about">
      
    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>About</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-tags">
      
    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>Tags</a>

  </li>
      <li class="menu-item menu-item-search">
        <a href="javascript:;" class="popup-trigger">
        
          <i class="menu-item-icon fa fa-search fa-fw"></i> <br>Search</a>
      </li>
    
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input" id="search-input"></div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="algolia-results">
  <div id="algolia-stats"></div>
  <div id="algolia-hits"></div>
  <div id="algolia-pagination" class="algolia-pagination"></div>
</div>

  
</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
            

          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
      <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block post">
    <link itemprop="mainEntityOfPage" href="https://zyplanet.github.io/2019/10/02/embedding as matrix factorizaiton/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="diphda">
      <meta itemprop="description" content="Please feel free to discuss with us about any questions.">
      <meta itemprop="image" content="https://z3.ax1x.com/2021/09/10/hjts9s.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="diphda">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">embedding as matrix factorizaiton

          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              
                
              

              <time title="Created: 2019-10-02 20:44:00" itemprop="dateCreated datePublished" datetime="2019-10-02T20:44:00+08:00">2019-10-02</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-09-17 19:08:04" itemprop="dateModified" datetime="2021-09-17T19:08:04+08:00">2021-09-17</time>
              </span>
            
          

          
            <span id="/2019/10/02/embedding as matrix factorizaiton/" class="post-meta-item leancloud_visitors" data-flag-title="embedding as matrix factorizaiton" title="Views">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span class="leancloud-visitors-count"></span>
            </span>
          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
        
      
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2019/10/02/embedding as matrix factorizaiton/#comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/2019/10/02/embedding as matrix factorizaiton/" itemprop="commentCount"></span></a>
  </span>
  
  
          <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
              
                <span class="post-meta-item-text">Symbols count in article: </span>
              
              <span>4k</span>
            </span>
          
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
              
                <span class="post-meta-item-text">Reading time &asymp;</span>
              
              <span>7 mins.</span>
            </span>
          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="Neural-Word-Embedding-as-Implicit-Matrix-Factorization"><a href="#Neural-Word-Embedding-as-Implicit-Matrix-Factorization" class="headerlink" title="Neural Word Embedding as Implicit Matrix Factorization"></a>Neural Word Embedding as Implicit Matrix Factorization</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>尽管嵌入模型很明显是基于分布假设来进行优化，使常出现的word-context对向量内积极大化，并极小化随机word-context对内积。但对于这些优化指标的讨论很少，也不清楚为什么这样能够得到期望的结果。这篇文章对此进行了探讨，表明SGNS(skip-gram with negative-sampling)的训练方法实际上是加权矩阵分解，其目标函数在隐式地分解一个移动PMI矩阵，并基于此提出了更高效的优化方式。</p><a id="more"></a>
<h2 id="SGNS"><a href="#SGNS" class="headerlink" title="SGNS"></a>SGNS</h2><p>关于skip-gram with negative-sampling，这里就不再赘述，请查看下面两篇文章：</p>
<ul>
<li><a href="https://arxiv.org/abs/1301.3781" target="_blank" rel="noopener">Efficient estimation of word representations in vector space</a></li>
<li><a href="https://arxiv.org/abs/1310.4546" target="_blank" rel="noopener">Distributed representations of words and phrases and their compositionality</a></li>
</ul>
<p>总的来说，SGNS的目标函数如下：</p>
<script type="math/tex; mode=display">
l=\Sigma_{w\in V_W}\Sigma_{c\in V_C}|(w,c)|(log\sigma(\vec{w}\cdot\vec{c})+k\cdot\mathbb{E}_{c_N\sim P_D}[log\sigma(-\vec{w}\cdot\vec{c}_N)])\tag{1}</script><p>这里$V_W$为单词集，$V_C$为上下文集，$P_D$为均匀测度满足$P_D(c)=\frac{|(c)|}{|D|}$.</p>
<h2 id="隐式矩阵分解下的SGNS"><a href="#隐式矩阵分解下的SGNS" class="headerlink" title="隐式矩阵分解下的SGNS"></a>隐式矩阵分解下的SGNS</h2><p>SGNS将单词以及上下文嵌入为低维空间的向量，得到单词与上下文向量构成的矩阵$W$与$C$，这两者实际上是相同的。$W$的行元素（即单词嵌入向量）被直接提取使用，但原始SG模型会进行上下文预测，SGNS可以看作是对矩阵$M=W\cdot C^T$的分解。</p>
<p>对于$M$，其分量$M_{i,j}$对应了$W_i,C_j$的向量积，这表示着特定单词与上下文的关联强度，而这种关联矩阵常常出现于NLP的研究中，但该矩阵并没有显式出现在SGNS的优化函数中，那么将SNGS看作对$M$的隐式分解说得通吗？如果不是，SGNS分解的是哪个矩阵呢？</p>
<h3 id="刻画该隐式矩阵"><a href="#刻画该隐式矩阵" class="headerlink" title="刻画该隐式矩阵"></a>刻画该隐式矩阵</h3><p>重写式子$(1)$:</p>
<script type="math/tex; mode=display">
\begin{aligned}
l&=\Sigma_{w\in V_W}\Sigma_{c\in V_C}|(w,c)|(log\sigma(\vec{w}\cdot\vec{c}))+\Sigma_{w\in V_W}\Sigma_{c\in V_C}\|(w,c)|(k\cdot\mathbb{E}_{c_N\sim P_D}[log\sigma(-\vec{w}\cdot\vec{c}_N)])\\
&=\Sigma_{w\in V_W}\Sigma_{c\in V_C}|(w,c)|(log\sigma(\vec{w}\cdot\vec{c}))+\Sigma_{w\in V_W}|(w)|(k\cdot\mathbb{E}_{c_N\sim P_D}[log\sigma(-\vec{w}\cdot\vec{c}_N)])
\end{aligned}\tag{2}</script><p>然后显式地计算出期望项：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\mathbb{E}_{c_N\sim P_D}[log\sigma(-\vec{w}\cdot\vec{c}_N)]&=\Sigma_{c_N\in V_C }\frac{|(c_N)|}{|D|}log\sigma(-\vec{w}\cdot\vec{c}_N)\\
&=\frac{|(c)|}{|D|}log\sigma(-\vec{w}\cdot\vec{c})+\Sigma_{c_N\in V_C\setminus \{c \}}\frac{|(c_N)|}{|D|}log\sigma(-\vec{w}\cdot\vec{c}_N)
\end{aligned}\tag{3}</script><p>结合两式并将$l$改写为局部形式：</p>
<script type="math/tex; mode=display">
l(w,c)=|(w,c)|log\sigma (\vec{w}\cdot \vec{c})+k\cdot |(w)|\cdot\frac{|(c)|}{|D|}log\sigma(-\vec{w}\cdot\vec{c})\tag{4}</script><p>定义$x=\vec{w}\cdot \vec{c}$，并对其求导：</p>
<script type="math/tex; mode=display">
\frac{\partial{l}}{\partial{x}}=|(w,c)|\cdot\sigma(-x)-k\cdot|(w)|\frac{|(c)|}{|D|}\sigma(x)</script><p>令其为零得到：</p>
<script type="math/tex; mode=display">
e^{2x}-(\frac{|(w,c)|}{k\cdot|(w)|\cdot\frac{|(c)|}{|D|}}-1)e^x-\frac{|(w,c)|}{k\cdot|(w)|\cdot\frac{|(c)|}{|D|}}=0</script><p>我们可以直接给出显式解：</p>
<script type="math/tex; mode=display">
\vec{w}\cdot \vec{c}=log(\frac{|(w,c)|\cdot|D|}{|(w)|\cdot |(c)|})-logk\tag{5}</script><p>这里指出$log(\frac{|(w,c)|\cdot|D|}{|(w)|\cdot |(c)|})$即$(w,c)$的PMI(pointwise mutual information)，PMI常见于nlp的研究中，可以进一步将上式写为：</p>
<script type="math/tex; mode=display">
M_{i,j}^{SGNS}=W_i\cdot C_j=\vec{w}_i\cdot\vec{c}_j=PMI(w_i,c_j)-logk\tag{6}</script><p>SGNS实际上在分解上述的矩阵，当$k=1$即负采样率为1时，SGNS的目标函数其实在分解由单词与上下文构成的关联矩阵，并且关联强度由PMI给出，这里将其定义为PMI阵，$M^{PMI}$. 当$k$变化时，对应的PMI阵会有所偏移，$M^{PMIk}=M^{PMI}-logk$.</p>
<p>其它的嵌入算法也可以相应理解，如noise-contrastive estimation模型分解的矩阵为：</p>
<script type="math/tex; mode=display">
M_{i,j}^{NCE}=\vec{w}_i\cdot \vec{c}_j=log(\frac{|(w,c)|}{|(c)|})-logk=logP(w|c)-logk\tag{7}</script><h3 id="PMI"><a href="#PMI" class="headerlink" title="PMI"></a>PMI</h3><p>PMI是信息理论中用于度量一对离散输出$x,y$的度量函数：</p>
<script type="math/tex; mode=display">
PMI(x,y) = log\frac{P(x,y)}{P(x)P(y)}\tag{8}</script><p>在进行词嵌入时，上面的概率完全是由计数来估计的：</p>
<script type="math/tex; mode=display">
PMI(w,c)=log\frac{|(w,c)|\cdot|D|}{|(w)|\cdot |(c)|}\tag{9}</script><p>上面所给的PMI估计并不是定义良好的，当不存在某个$(w,c)$对时，对应的估计将为负无穷，一个修改方式是将负无穷的分量重整为0。但考虑PMI的语义，这并不合理，更好的做法是将负值全都置为零，这称为postive PMI(PPMI)：</p>
<script type="math/tex; mode=display">
PPMI(w,c)=\max(PMI(w,c),0)\tag{10}</script><h2 id="词嵌入的其它选择"><a href="#词嵌入的其它选择" class="headerlink" title="词嵌入的其它选择"></a>词嵌入的其它选择</h2><p>首先由前面的推导，很容易得到下面的shifted PPMI:</p>
<script type="math/tex; mode=display">
SPPMI_k(w,c)=\max (PMI(w,c)-logk,0)\tag{11}</script><h3 id="谱降维：SVD-over-Shifted-PPMI"><a href="#谱降维：SVD-over-Shifted-PPMI" class="headerlink" title="谱降维：SVD over Shifted PPMI"></a>谱降维：SVD over Shifted PPMI</h3><p>如果将SGNS理解为矩阵分解，那么通常的矩阵分解也可以直接用于求解词嵌入，这里使用truncated SVD.</p>
<p>SVD将M分解为三个矩阵的乘积$U\cdot \Sigma \cdot V^T$，这里$U$和$V$是正交阵，$\Sigma$为奇异值构成的对角阵。令$\Sigma_d$为前$d$个奇异值构成的对角阵，$U_d$和$V_d$为从$U,V$对应列抽出的子阵。$M_d=U_d\cdot \Sigma_d \cdot V_d^T$为$M$的秩$d$最佳估计，即有$M_d=\mathop{\arg\min}\limits_{Rank(M’)=d}||M’-M||_2$成立.</p>
<p>如果使用SVD，那么$W=U_d \cdot \Sigma_d$行间的向量积等于$M_D$行间的向量积，使用$W$足够作为$M_D$的低维稠密表示。在NLP的研究中，一个常见方法是对PPMI矩阵$M^{PPMI}$进行SVD分解，并使用$W^{SVD}=U_d\cdot \Sigma_d$以及$C^{SVD}=V_D$的行元素分别作为单词与上下文表示。但这种方法得到的结果在语义任务上总是达不到SGNS的性能。</p>
<p><strong>对称SVD</strong></p>
<p>如果直接使用SVD来分解，那么最终得到的单词、上下文嵌入阵会相当不同，仅$C^{SVD}$为正交的，SGNS方法相比显得更加对称，故而这里使用如下的分解：</p>
<script type="math/tex; mode=display">
W^{SVD_{1/2}}=U_D\cdot \sqrt{\Sigma_d}\quad C^{SVD_{1/2}}=V_d\cdot \sqrt{\Sigma_d}\tag{12}</script><p>尽管缺乏理论解释，但在实践中进行对称化后能得到更好的性能。</p>
<p><strong>SVD versus SGNS</strong></p>
<p>SVD不需要训练以及超参数的调整，对任何$\{(w,c,|(w,c)|)\}$形式的数据都可以使用，泛用性更高。</p>
<p>而SGNS可以更好地处理观察，未观察事件；除此之外， SGNS对不同$(w,c)$对分配了不同权重，这对于SVD来说是相当困难的，对于非稀疏的矩阵SGNS拥有更高的分解效率。</p>
<p>一个有趣的想法是使用随机矩阵分解，作者将其放在未来工作中。</p>
<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p>个人觉得理论仍然不太充分，有些地方还是有点自圆其说，实验结果还过得去。</p>
<p><img src="https://zyplanethome.files.wordpress.com/2019/10/svd1.png" alt="table1"></p>
<p><img src="https://zyplanethome.files.wordpress.com/2019/10/svd2.png" alt="table2"></p>

    </div>

    
    
    
        
      

      <footer class="post-footer">
          
            
          
          <div class="post-tags">
            
              <a href="/tags/Representation-Learning/" rel="tag"># Representation Learning</a>
            
          </div>
        

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
              
                <a href="/2019/09/01/secure aggregation for federated learning/" rel="next" title="secure aggregation for federated learning">
                  <i class="fa fa-chevron-left"></i> secure aggregation for federated learning
                </a>
              
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
              
                <a href="/2020/09/14/Strong Convexity/" rel="prev" title="Strong Convexity">
                  Strong Convexity <i class="fa fa-chevron-right"></i>
                </a>
              
            </div>
          </div>
        
      </footer>
    
  </div>
  
  
  
  </article>

  </div>


          </div>
          
    
    <div class="comments" id="comments"></div>
  

        </div>
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">
        
        
        
        
      

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc" data-target="post-toc-wrap">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview" data-target="site-overview-wrap">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Neural-Word-Embedding-as-Implicit-Matrix-Factorization"><span class="nav-number">1.</span> <span class="nav-text">Neural Word Embedding as Implicit Matrix Factorization</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#前言"><span class="nav-number">1.1.</span> <span class="nav-text">前言</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SGNS"><span class="nav-number">1.2.</span> <span class="nav-text">SGNS</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#隐式矩阵分解下的SGNS"><span class="nav-number">1.3.</span> <span class="nav-text">隐式矩阵分解下的SGNS</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#刻画该隐式矩阵"><span class="nav-number">1.3.1.</span> <span class="nav-text">刻画该隐式矩阵</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#PMI"><span class="nav-number">1.3.2.</span> <span class="nav-text">PMI</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#词嵌入的其它选择"><span class="nav-number">1.4.</span> <span class="nav-text">词嵌入的其它选择</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#谱降维：SVD-over-Shifted-PPMI"><span class="nav-number">1.4.1.</span> <span class="nav-text">谱降维：SVD over Shifted PPMI</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#实验结果"><span class="nav-number">1.5.</span> <span class="nav-text">实验结果</span></a></li></ol></li></ol></div>
        
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image"
      src="https://z3.ax1x.com/2021/09/10/hjts9s.jpg"
      alt="diphda">
  <p class="site-author-name" itemprop="name">diphda</p>
  <div class="site-description" itemprop="description">Please feel free to discuss with us about any questions.</div>
</div>
  <nav class="site-state motion-element">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives">
        
          <span class="site-state-item-count">12</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-tags">
        
          
            <a href="/tags/">
          
        
        
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">tags</span>
        </a>
      </div>
    
  </nav>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="https://github.com/zyplanet" title="GitHub &rarr; https://github.com/zyplanet" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
    
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="mailto:diphda@zju.edu.cn" title="E-Mail &rarr; mailto:diphda@zju.edu.cn" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
    
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title">
      <i class="fa fa-fw fa-link"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://zjuvag.org/" title="https://zjuvag.org/" rel="noopener" target="_blank">VAG</a>
        </li>
      
        <li class="links-of-blogroll-item">
          <a href="https://Fenghz.github.io" title="https://Fenghz.github.io" rel="noopener" target="_blank">FHZ</a>
        </li>
      
        <li class="links-of-blogroll-item">
          <a href="https://www.jarvis73.com" title="https://www.jarvis73.com" rel="noopener" target="_blank">ZJW</a>
        </li>
      
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">diphda</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    <span title="Symbols count total">51k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="Reading time total">1:24</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.9.0</div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v7.3.0</div>

        






  
  <script>
  function leancloudSelector(url) {
    return document.getElementById(url).querySelector('.leancloud-visitors-count');
  }
  if (CONFIG.page.isPost) {
    function addCount(Counter) {
      var visitors = document.querySelector('.leancloud_visitors');
      var url = visitors.getAttribute('id').trim();
      var title = visitors.getAttribute('data-flag-title').trim();

      Counter('get', `/classes/Counter?where=${JSON.stringify({ url })}`)
        .then(response => response.json())
        .then(({ results }) => {
          if (results.length > 0) {
            var counter = results[0];
            Counter('put', '/classes/Counter/' + counter.objectId, { time: { '__op': 'Increment', 'amount': 1 } })
              .then(response => response.json())
              .then(() => {
                leancloudSelector(url).innerText = counter.time + 1;
              })
            
              .catch(error => {
                console.log('Failed to save visitor count', error);
              })
          } else {
              leancloudSelector(url).innerText = 'Counter not initialized! More info at console err msg.';
              console.error('ATTENTION! LeanCloud counter has security bug, see how to solve it here: https://github.com/theme-next/hexo-leancloud-counter-security. \n However, you can still use LeanCloud without security, by setting `security` option to `false`.');
            
          }
        })
        .catch(error => {
          console.log('LeanCloud Counter Error', error);
        });
    }
  } else {
    function showTime(Counter) {
      var visitors = document.querySelectorAll('.leancloud_visitors');
      var entries = [...visitors].map(element => {
        return element.getAttribute('id').trim();
      });

      Counter('get', `/classes/Counter?where=${JSON.stringify({ url: { '$in': entries } })}`)
        .then(response => response.json())
        .then(({ results }) => {
          if (results.length === 0) {
            document.querySelectorAll('.leancloud_visitors .leancloud-visitors-count').forEach(element => {
              element.innerText = 0;
            });
            return;
          }
          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.url;
            var time = item.time;
            leancloudSelector(url).innerText = time;
          }
          for (var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = leancloudSelector(url);
            if (element.innerText == '') {
              element.innerText = 0;
            }
          }
        })
        .catch(error => {
          console.log('LeanCloud Counter Error', error);
        });
    }
  }

  fetch('https://app-router.leancloud.cn/2/route?appId=XuyqBYjh1vSXlsMsAetCJ09J-gzGzoHsz')
    .then(response => response.json())
    .then(({ api_server }) => {
      var Counter = (method, url, data) => {
        return fetch(`https://${api_server}/1.1${url}`, {
          method: method,
          headers: {
            'X-LC-Id': 'XuyqBYjh1vSXlsMsAetCJ09J-gzGzoHsz',
            'X-LC-Key': 'xOD8ROp7U0J7WzmMX7nJPqD4',
            'Content-Type': 'application/json',
          },
          body: JSON.stringify(data)
        });
      };
      if (CONFIG.page.isPost) {
        const localhost = /http:\/\/(localhost|127.0.0.1|0.0.0.0)/;
        if (localhost.test(document.URL)) return;
        addCount(Counter);
      } else if (document.querySelectorAll('.post-title-link').length >= 1) {
        showTime(Counter);
      }
    });
  </script>






        
      </div>
    </footer>
  </div>

  
  <script src="/lib/jquery/index.js?v=3.4.1"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
<script src="/js/utils.js?v=7.3.0"></script><script src="/js/motion.js?v=7.3.0"></script>
<script src="/js/schemes/pisces.js?v=7.3.0"></script>
<script src="/js/next-boot.js?v=7.3.0"></script>



  








  
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/instantsearch.js@2/dist/instantsearch.min.css">
<script src="//cdn.jsdelivr.net/npm/instantsearch.js@2/dist/instantsearch.min.js"></script><script src="/js/algolia-search.js?v=7.3.0"></script>















  

  
    
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    
  

  

  


<script>
NexT.utils.getScript('//cdn.jsdelivr.net/npm/valine/dist/Valine.min.js', () => {
  var GUEST = ['nick', 'mail', 'link'];
  var guest = 'nick,mail';
  guest = guest.split(',').filter(item => {
    return GUEST.indexOf(item) > -1;
  });
  new Valine({
    el: '#comments',
    verify: false,
    notify: false,
    appId: 'XuyqBYjh1vSXlsMsAetCJ09J-gzGzoHsz',
    appKey: 'xOD8ROp7U0J7WzmMX7nJPqD4',
    placeholder: 'say something?',
    avatar: 'mm',
    meta: guest,
    pageSize: '10' || 10,
    visitor: false,
    lang: '' || 'zh-cn',
    path: location.pathname
  });
}, window.Valine);
</script>

</body>
</html>
